{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vseeq7xvh2k2",
        "outputId": "08678bfc-950b-4b37-da71-6a0af7ad7ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/breast-histopathology-images?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.10G/3.10G [00:24<00:00, 137MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/paultimothymooney/breast-histopathology-images/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrBCEF3Hk_QS"
      },
      "source": [
        "### **Preprocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCLiOw0Mi3Ag",
        "outputId": "cb3cd72a-6202-4408-96b3-be104754d96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 444147 images belonging to 280 classes.\n",
            "Found 110901 images belonging to 280 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define augmentation strategies\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # Splitting dataset into training and validation\n",
        ")\n",
        "\n",
        "# Loading and augmenting dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size=(224, 224),  # Resize images\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl2K1YfvlKG4"
      },
      "source": [
        "### **Building the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIIIvO-qjy58",
        "outputId": "320dd9b6-e9ad-41e7-910a-ef0ab00db55b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p76EfFMsLs0U"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-7-ESC4LxRB",
        "outputId": "1d7d5f4f-1962-4f8e-cf99-4c3c5875e178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m2302/6940\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m59:49\u001b[0m 774ms/step - accuracy: 0.0013 - loss: -71086888479358976.0000"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5EuvYnWGcL0"
      },
      "source": [
        "### **Highlighting the cancerous regions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfX01PPgmBT3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Grad-CAM implementation\n",
        "def grad_cam(model, img_path, layer_name='block5_conv3'):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    grad_model = Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, 0]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)[0]\n",
        "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
        "    cam = np.dot(conv_outputs[0], weights)\n",
        "\n",
        "    cam = tf.maximum(cam, 0) / tf.math.reduce_max(cam)\n",
        "    cam = tf.image.resize(cam[..., np.newaxis], (224, 224)).numpy()\n",
        "\n",
        "    # Overlay the heatmap\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(cam[..., 0], cmap='jet', alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Test on a sample image\n",
        "grad_cam(model, 'path_to_test_image.jpg', layer_name='block5_conv3')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tehLPc1BGnp3"
      },
      "source": [
        "### **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1KcCFb4mEtg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_images, val_labels = next(iter(validation_generator))\n",
        "predictions = model.predict(val_images) > 0.5\n",
        "\n",
        "print(classification_report(val_labels, predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSdd49pRGIka"
      },
      "source": [
        "### **Using Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdXKjg3umAI9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze layers to prevent retraining\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=4)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}